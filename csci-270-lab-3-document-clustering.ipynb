{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# CSCI 270 - Computational Humanities\n# Lab 3 - Document Clustering","metadata":{}},{"cell_type":"code","source":"from scipy.cluster import hierarchy\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport math\nimport os\nimport re\nfrom typing import *\nfrom numpy.linalg import norm ","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:33.265119Z","iopub.execute_input":"2022-02-13T21:27:33.265559Z","iopub.status.idle":"2022-02-13T21:27:33.632334Z","shell.execute_reply.started":"2022-02-13T21:27:33.265429Z","shell.execute_reply":"2022-02-13T21:27:33.631574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup\n\nAdd the CSCI 270 Books and Poems data sets to this notebook's data.\n\nAs we develop functions to enable us to perform data clustering, we will use the dictionary given below. Later on, once our functions are working, we will load our documents from files into a dictionary with the same setup, where the keys are filenames (serving as document titles) and the values are the documents themselves.","metadata":{}},{"cell_type":"code","source":"filename2document = {\"A\": \"wet snow falls in winter snow falls\", \n                     \"B\": \"cold and wet in winter\", \n                     \"C\": \"cold wet snow packs best best\", \n                     \"D\": \"cold snow is cold and wet\"}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:33.956669Z","iopub.execute_input":"2022-02-13T21:27:33.956988Z","iopub.status.idle":"2022-02-13T21:27:33.961741Z","shell.execute_reply.started":"2022-02-13T21:27:33.956951Z","shell.execute_reply":"2022-02-13T21:27:33.96079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The `assess()` function returns `True` if its parameters match, and `False` otherwise. It also prints out the first value. We will use this function to test each of the functions we write.","metadata":{}},{"cell_type":"code","source":"def assess(value, expected):\n    print(value)\n    return value == expected","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.479426Z","iopub.execute_input":"2022-02-13T21:27:34.479971Z","iopub.status.idle":"2022-02-13T21:27:34.484861Z","shell.execute_reply.started":"2022-02-13T21:27:34.479927Z","shell.execute_reply":"2022-02-13T21:27:34.483577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lab 2 Functions\n\nIn the code block below, copy over the following functions you wrote in Lab 2:\n* `file_dictionary()`\n* `all_tokens_from()`\n* `count()`\n* `count_all()`","metadata":{}},{"cell_type":"code","source":"def file_dictionary(file_path: str) -> Dict[str,str]:\n    dict = {}\n    for file in os.listdir(file_path):\n        dict[file] = open(file_path + '/' +  file).read()\n    return dict\n\ndef all_unique_tokens_from(text: str) -> List[str]:\n    unique = []\n    for word in all_tokens_from(text):\n        if word not in unique:\n            unique.append(word)\n    return unique\n    \ndef all_tokens_from(text: str) -> List[str]:\n    token = text.replace('.', '').lower().split()\n    return token\n\ndef count(histogram: Dict[Hashable,int], item: Hashable):\n    if item not in histogram:\n        histogram[item] = 1\n    else:\n        histogram[item]+=1\n    return\n    \ndef count_all(items: Iterable[Hashable]) -> Dict[Hashable,int]:\n    return {word:items.count(word) for word in items}","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.555165Z","iopub.execute_input":"2022-02-13T21:27:34.555657Z","iopub.status.idle":"2022-02-13T21:27:34.568119Z","shell.execute_reply.started":"2022-02-13T21:27:34.555605Z","shell.execute_reply":"2022-02-13T21:27:34.567206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 1 - Finding tf-idf matrix\n\nWrite a function to find the term frequencies for all documents. It should return a dictionary, where the key is the name of the file, and the value is a dictionary of term frequency counts.","metadata":{}},{"cell_type":"code","source":"def term_freqs(data: Dict[str,str]) -> Dict[str,Dict[str,int]]:\n    count_dis = {}\n    for filename, contents in data.items():\n        temp = {}\n        count_dis[filename] = temp\n        for word in all_tokens_from(contents):\n            if word in temp:\n                temp[word] += 1\n            else:\n                temp[word] = 1\n    return(count_dis)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.648601Z","iopub.execute_input":"2022-02-13T21:27:34.650875Z","iopub.status.idle":"2022-02-13T21:27:34.658627Z","shell.execute_reply.started":"2022-02-13T21:27:34.650826Z","shell.execute_reply":"2022-02-13T21:27:34.657763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf = term_freqs(filename2document)\nassess(tf, {'A': {'wet': 1, 'snow': 2, 'falls': 2, 'in': 1, 'winter': 1},\n            'B': {'cold': 1, 'and': 1, 'wet': 1, 'in': 1, 'winter': 1},\n            'C': {'cold': 1, 'wet': 1, 'snow': 1, 'packs': 1, 'best': 2},\n            'D': {'cold': 2, 'snow': 1, 'is': 1, 'and': 1, 'wet': 1}})","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.66981Z","iopub.execute_input":"2022-02-13T21:27:34.670114Z","iopub.status.idle":"2022-02-13T21:27:34.686596Z","shell.execute_reply.started":"2022-02-13T21:27:34.670081Z","shell.execute_reply":"2022-02-13T21:27:34.685919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to return a **sorted** list of all words in the corpus. By using an object of the $set()$ class as an intermediate step, we facilitate fast lookup when checking for uniqueness.","metadata":{}},{"cell_type":"code","source":"def all_terms(filename2document: Dict[str,Dict[str,int]]) -> List[str]:\n    term_list = set()\n    for filename, contents in filename2document.items():\n        term_list.add(contents)\n    term_list = ' '.join(term_list)\n    term_list = all_unique_tokens_from(term_list)\n    term_list = sorted(term_list)\n    return term_list\n#    set_list = []\n#    for name, words in filename2document.items():\n#        for item in words.split():\n#            print(item)\n#            if item not in set_list:\n#                count = 0\n#                if len(set_list) == 0 :\n#                    set_list.append(item)\n#                for wrd in set_list:\n#                    if wrd > item:\n#                        continue\n#                    if wrd < item:\n#                        set_list.insert(count, item)\n#                    count += 1\n#            else:\n#                continue\n#    return set_list","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.7332Z","iopub.execute_input":"2022-02-13T21:27:34.733497Z","iopub.status.idle":"2022-02-13T21:27:34.739627Z","shell.execute_reply.started":"2022-02-13T21:27:34.733469Z","shell.execute_reply":"2022-02-13T21:27:34.738954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"terms = all_terms(filename2document) \nassess(terms, ['and', 'best', 'cold', 'falls', 'in', 'is', 'packs', 'snow', 'wet', 'winter'])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.842921Z","iopub.execute_input":"2022-02-13T21:27:34.843947Z","iopub.status.idle":"2022-02-13T21:27:34.850219Z","shell.execute_reply.started":"2022-02-13T21:27:34.843909Z","shell.execute_reply":"2022-02-13T21:27:34.849523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to return a dictionary where the keys are the words in the corpus and the values are the inverse document frequency for that term. Again, to make this efficient, make use of the $set()$ class. In the formula below, $N$ is the total number of documents in the collection, and $|\\{d \\in D : t \\in d\\}|$ is the number of documents in which the term $t$ appears.\n\n$$idf(t, D) = log\\frac{N}{|\\{d \\in D : t \\in d\\}|}$$","metadata":{}},{"cell_type":"code","source":"def inv_doc_freqs(data: Dict[str,str], terms: List[str]) -> Dict[str,float]:\n    dis_list = []\n    for i in data.values():\n        dis_list.append(set(all_tokens_from(i)))\n    N = len(data)\n    finale = {}\n    for x in terms:\n        num = 0\n        for y in dis_list:\n            if x in y:\n                num += 1\n        if num > 0:\n            idf = math.log(N/num)\n        else:\n            idf = 0.0\n        finale[x]=idf\n    return finale","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.864667Z","iopub.execute_input":"2022-02-13T21:27:34.865305Z","iopub.status.idle":"2022-02-13T21:27:34.873539Z","shell.execute_reply.started":"2022-02-13T21:27:34.86527Z","shell.execute_reply":"2022-02-13T21:27:34.872925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idf = inv_doc_freqs(filename2document, terms)\nassess(idf,\n       {'and': 0.6931471805599453,\n        'best': 1.3862943611198906,\n        'cold': 0.28768207245178085,\n        'falls': 1.3862943611198906,\n        'in': 0.6931471805599453,\n        'is': 1.3862943611198906,\n        'packs': 1.3862943611198906,\n        'snow': 0.28768207245178085,\n        'wet': 0.0,\n        'winter': 0.6931471805599453})","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.959868Z","iopub.execute_input":"2022-02-13T21:27:34.960151Z","iopub.status.idle":"2022-02-13T21:27:34.969902Z","shell.execute_reply.started":"2022-02-13T21:27:34.960121Z","shell.execute_reply":"2022-02-13T21:27:34.968801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function that returns a 2D matrix, with a column for each word in the corpus, and a row for each document in the corpus. The values for a row and column will be the tf-idf score for that word in that document.","metadata":{}},{"cell_type":"code","source":"def find_tfidf(tf: Dict[str,Dict[str,int]], idf: Dict[str,float], terms: List[str]) -> List[List[float]]:\n    N = len(tf)\n    tfidf = []\n    for c in tf:\n        sublist = []\n        for i in terms:\n            current= tf.get(c)\n            if i in current:\n                tf_sc = current.get(i)\n                idf_sc = idf.get(i)\n                score = tf_sc * idf_sc\n            else:\n                score = 0.0\n            sublist.append(score)\n        tfidf.append(sublist)\n    return tfidf","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:34.978816Z","iopub.execute_input":"2022-02-13T21:27:34.979065Z","iopub.status.idle":"2022-02-13T21:27:34.986592Z","shell.execute_reply.started":"2022-02-13T21:27:34.979039Z","shell.execute_reply":"2022-02-13T21:27:34.985881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The function below will print our small Snow matrix in a readable format. \n\n**Note:** This function will be useless on the larger datasets with many unique words.","metadata":{}},{"cell_type":"code","source":"def pretty_matrix(col_head: List[str], row_head: List[str], matrix: List[List[float]]):\n    top = \"   \"\n    for t in col_head:\n        top += '{:7s}'.format(t)\n    print(top)\n    for i in range(len(matrix)):\n        d = matrix[i]\n        s = row_head[i] + \": \"\n        for f in d:\n            s += f'{f:5.3f}' + \"  \"\n        print(s)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.07186Z","iopub.execute_input":"2022-02-13T21:27:35.07228Z","iopub.status.idle":"2022-02-13T21:27:35.078011Z","shell.execute_reply.started":"2022-02-13T21:27:35.072251Z","shell.execute_reply":"2022-02-13T21:27:35.077119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf = find_tfidf(tf, idf, terms)\npretty_matrix(terms, list(filename2document.keys()), tfidf)\ntfidf == [[0.0, 0.0, 0.0, 2.772588722239781, 0.6931471805599453, 0.0, 0.0, 0.5753641449035617, 0.0, 0.6931471805599453], \n          [0.6931471805599453, 0.0, 0.28768207245178085, 0.0, 0.6931471805599453, 0.0, 0.0, 0.0, 0.0, 0.6931471805599453], \n          [0.0, 2.772588722239781, 0.28768207245178085, 0.0, 0.0, 0.0, 1.3862943611198906, 0.28768207245178085, 0.0, 0.0], \n          [0.6931471805599453, 0.0, 0.5753641449035617, 0.0, 0.0, 1.3862943611198906, 0.0, 0.28768207245178085, 0.0, 0.0]]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.103287Z","iopub.execute_input":"2022-02-13T21:27:35.103736Z","iopub.status.idle":"2022-02-13T21:27:35.114552Z","shell.execute_reply.started":"2022-02-13T21:27:35.103693Z","shell.execute_reply":"2022-02-13T21:27:35.113765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 2 - Distance Matrix and Cosine Similarity","metadata":{}},{"cell_type":"markdown","source":"Write a function to calculate the dot product of two vectors $\\bf{a}$ and $\\bf{b}$.\n\n$$\\mathbf{a} \\cdot \\mathbf{b} = \\sum_{i=1}^{n} a_ib_i$$","metadata":{}},{"cell_type":"code","source":"def dot_product(a: List[float], b: List[float]) -> float:\n    return np.dot(a,b)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.235958Z","iopub.execute_input":"2022-02-13T21:27:35.236263Z","iopub.status.idle":"2022-02-13T21:27:35.240848Z","shell.execute_reply.started":"2022-02-13T21:27:35.236231Z","shell.execute_reply":"2022-02-13T21:27:35.240127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(dot_product([1,  2,  3], [4,  8, 12]), 56) and\\\nassess(dot_product([1,  2,  3], [4,  5,  6]), 32) and\\\nassess(dot_product([1,  2,  3], [1,  1,  1]),  6) and\\\nassess(dot_product([1,  2,  3], [3,  2,  1]), 10) and\\\nassess(dot_product([3,  0,  3], [0,  3,  0]),  0)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.348639Z","iopub.execute_input":"2022-02-13T21:27:35.349505Z","iopub.status.idle":"2022-02-13T21:27:35.359958Z","shell.execute_reply.started":"2022-02-13T21:27:35.349464Z","shell.execute_reply":"2022-02-13T21:27:35.359086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to calculate the cosine similarity of two vectors $\\bf{a}$ and $\\bf{b}$.\n\n$$cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{||\\mathbf{a}||~||\\mathbf{b}||}$$\n\nwhere \n\n$$||\\mathbf{a}|| = \\sqrt{\\mathbf{a} \\cdot \\mathbf{a}}$$","metadata":{}},{"cell_type":"code","source":"def cosine_sim(a: List[float], b: List[float]) -> float:\n    cosine = np.dot(a,b)\n    a = np.dot(a,a)\n    b = np.dot(b,b)\n    av = math.sqrt(a)\n    bv = math.sqrt(b)\n    abv = av * bv\n    cos = cosine/abv\n    return cos\n    #for item_a in a:\n    #    count = 0\n    #    for item_b in b:\n    #        over = item_a * item_b\n    #        under = (math.sqrt(item_a * item_a) )   \n    #for item_b in b:\n    #    print('b:')\n    #    print(item_b)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.366152Z","iopub.execute_input":"2022-02-13T21:27:35.366557Z","iopub.status.idle":"2022-02-13T21:27:35.372952Z","shell.execute_reply.started":"2022-02-13T21:27:35.366521Z","shell.execute_reply":"2022-02-13T21:27:35.372079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(cosine_sim([1,  2,  3], [4,  8, 12]), 1.0) and\\\nassess(cosine_sim([1,  2,  3], [4,  5,  6]), 0.9746318461970762) and\\\nassess(cosine_sim([1,  2,  3], [1,  1,  1]), 0.9258200997725515) and\\\nassess(cosine_sim([1,  2,  3], [3,  2,  1]), 0.7142857142857143) and\\\nassess(cosine_sim([3,  0,  3], [0,  3,  0]), 0.0)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.432074Z","iopub.execute_input":"2022-02-13T21:27:35.433024Z","iopub.status.idle":"2022-02-13T21:27:35.44408Z","shell.execute_reply.started":"2022-02-13T21:27:35.432981Z","shell.execute_reply":"2022-02-13T21:27:35.443332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to calculate the distance matrix between all row vectors in our tf-idf matrix. The distance should be $1-cosine\\_sim$.","metadata":{}},{"cell_type":"code","source":"def dist_matrix(vecs: List[List[float]]) -> List[List[float]]:\n    dist = []\n    c = 0 \n    for i in vecs:\n        new_list=[]\n        d = 0\n        for k in vecs:\n            total = 1 - cosine_sim(vecs[c], vecs[d])\n            new_list.append(total)\n            d+=1\n        c+=1\n        dist.append(new_list)\n    return dist","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.580893Z","iopub.execute_input":"2022-02-13T21:27:35.58138Z","iopub.status.idle":"2022-02-13T21:27:35.587845Z","shell.execute_reply.started":"2022-02-13T21:27:35.581348Z","shell.execute_reply":"2022-02-13T21:27:35.586802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dmat = dist_matrix(tfidf)\npretty_matrix(list(filename2document), list(filename2document), dmat)\ndmat == [[0.0, 0.740251794063685, 0.982331986879515, 0.9670833903997196], \n         [0.740251794063685, 1.1102230246251565e-16, 0.9785579200110728, 0.6881940602419325], \n         [0.982331986879515, 0.9785579200110728, 2.220446049250313e-16, 0.952676589993446], \n         [0.9670833903997196, 0.6881940602419325, 0.952676589993446, -2.220446049250313e-16]]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.589679Z","iopub.execute_input":"2022-02-13T21:27:35.589972Z","iopub.status.idle":"2022-02-13T21:27:35.606893Z","shell.execute_reply.started":"2022-02-13T21:27:35.589942Z","shell.execute_reply":"2022-02-13T21:27:35.606143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 3 - Clustering with UPGMA","metadata":{}},{"cell_type":"markdown","source":"The UPGMA algorithm enables us to visualize groups of related documents. It is fairly complex to implement, so we will write a series of helper functions for it. \n\nFirst, let's write a function to copy a nested list. To copy a regular list in Python, we can slice the whole thing. Run the code block below:","metadata":{}},{"cell_type":"code","source":"nums1 = [1, 2, 3, 4]\nnums2 = nums1[:]\nnums2[0] = 10\nprint(nums1)\nprint(nums2)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.714104Z","iopub.execute_input":"2022-02-13T21:27:35.714551Z","iopub.status.idle":"2022-02-13T21:27:35.721219Z","shell.execute_reply.started":"2022-02-13T21:27:35.714515Z","shell.execute_reply":"2022-02-13T21:27:35.720022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But if a list is nested, this performs a **shallow copy**:","metadata":{}},{"cell_type":"code","source":"m1 = [[1, 2], [3, 4]]\nm2 = m1[:]\nm2[0][0] = 10\nprint(m1)\nprint(m2)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.729682Z","iopub.execute_input":"2022-02-13T21:27:35.730087Z","iopub.status.idle":"2022-02-13T21:27:35.737532Z","shell.execute_reply.started":"2022-02-13T21:27:35.73005Z","shell.execute_reply":"2022-02-13T21:27:35.736379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to create a **deep copy** of a nested list. Assume the list is a matrix - that is, it is only nested at one level of depth.","metadata":{}},{"cell_type":"code","source":"def nested_copy(matrix: List) -> List: \n    return [row[:] for row in matrix]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.944429Z","iopub.execute_input":"2022-02-13T21:27:35.944718Z","iopub.status.idle":"2022-02-13T21:27:35.950142Z","shell.execute_reply.started":"2022-02-13T21:27:35.944675Z","shell.execute_reply":"2022-02-13T21:27:35.949176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m1 = [[1, 2], [3, 4]]\nm2 = nested_copy(m1)\nm2[0][0] = 10\nassess(m1, [[1, 2], [3, 4]])\nassess(m2, [[10, 2], [3, 4]])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.957056Z","iopub.execute_input":"2022-02-13T21:27:35.957308Z","iopub.status.idle":"2022-02-13T21:27:35.967398Z","shell.execute_reply.started":"2022-02-13T21:27:35.957281Z","shell.execute_reply":"2022-02-13T21:27:35.966794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to calculate the nearest pair of documents when given a matrix of distances between them. The function should return a tuple listing the index of the first document, the index of the second document, and their distance. Ignore all indices in the `prohobited` set.\n\n**Note**: The two documents should be **distinct**.","metadata":{}},{"cell_type":"code","source":"def nearest(matrix: List[List[float]], prohibited: Set[int]) -> Tuple[int, int, float]:\n    currentlow = 1\n    currenti = None\n    currentk = None\n    c = 0\n    for i in matrix:\n        d = 0\n        for k in matrix[c]:\n            if c not in prohibited and d not in prohibited:\n                if currenti is None or matrix[c][d] < currentlow:\n                    if c != d:\n                        currentlow = matrix[c][d]\n                        currenti=c\n                        currentk=d\n            d +=1                \n        c+=1\n    tuple_data=(currenti, currentk, currentlow)\n    return tuple_data","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:35.972076Z","iopub.execute_input":"2022-02-13T21:27:35.972694Z","iopub.status.idle":"2022-02-13T21:27:35.982817Z","shell.execute_reply.started":"2022-02-13T21:27:35.972654Z","shell.execute_reply":"2022-02-13T21:27:35.981883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(nearest(dmat, set()), (1, 3, 0.6881940602419325)) and\\\nassess(nearest(dmat, {1, 3}), (0, 2, 0.982331986879515))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.002737Z","iopub.execute_input":"2022-02-13T21:27:36.003015Z","iopub.status.idle":"2022-02-13T21:27:36.01146Z","shell.execute_reply.started":"2022-02-13T21:27:36.002987Z","shell.execute_reply":"2022-02-13T21:27:36.010806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clusters are defined by a list with 4 values:\n\n* index of first child\n* index of second child\n* distance between children\n* number of documents in the cluster\n\nThis is a function to create the list of initial clusters for the leaves in our tree. We have one cluster for each of our original documents.","metadata":{}},{"cell_type":"code","source":"def init_clusters(matrix: List[List[float]]) -> List[Tuple[int, int, float, int]]:\n    a=0\n    cluster_list=[]\n    while a < len(matrix): \n        tuple_data=(a, a, 0, 1)\n        cluster_list.append(tuple_data)\n        a+=1\n    return cluster_list","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.10834Z","iopub.execute_input":"2022-02-13T21:27:36.109109Z","iopub.status.idle":"2022-02-13T21:27:36.11517Z","shell.execute_reply.started":"2022-02-13T21:27:36.109069Z","shell.execute_reply":"2022-02-13T21:27:36.114193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(init_clusters(dmat), [(0, 0, 0, 1), (1, 1, 0, 1), (2, 2, 0, 1), (3, 3, 0, 1)])\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.120645Z","iopub.execute_input":"2022-02-13T21:27:36.120959Z","iopub.status.idle":"2022-02-13T21:27:36.23517Z","shell.execute_reply.started":"2022-02-13T21:27:36.120929Z","shell.execute_reply":"2022-02-13T21:27:36.233983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Write a function to calculate the unweighted distance of a new cluster formed from $A$ and $B$ to another cluster $X$, when given the size of the clusters $A$ and $B$ and their distances to $X$. This will be used in the UPGMA algorithm below.\n\n$$d_{(A \\cup B),X} = \\frac{|A|~d_{A,X}~+~|B|~d_{B,X}}{|A|~+~|B|}$$","metadata":{}},{"cell_type":"code","source":"def new_dist(a_size: int, b_size: int, d_a_x: float, d_b_x: float) -> float:\n    return (abs(a_size)*d_a_x+abs(b_size)*d_b_x)/(abs(a_size+b_size))","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.237154Z","iopub.execute_input":"2022-02-13T21:27:36.237613Z","iopub.status.idle":"2022-02-13T21:27:36.24708Z","shell.execute_reply.started":"2022-02-13T21:27:36.237568Z","shell.execute_reply":"2022-02-13T21:27:36.246162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(new_dist(1, 1, 0.740, 0.967), 0.8534999999999999) and\\\nassess(new_dist(2, 1, 0.740, 0.967), 0.8156666666666667)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.255483Z","iopub.execute_input":"2022-02-13T21:27:36.25575Z","iopub.status.idle":"2022-02-13T21:27:36.264275Z","shell.execute_reply.started":"2022-02-13T21:27:36.255713Z","shell.execute_reply":"2022-02-13T21:27:36.26328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"When `nearest()` finds the two closest clusters and the row indices corresponding to them, we need to create a new row corresponding to the new cluster we get when we combine them.\n\nGiven a matrix `m`, row indices `row_a` and `row_b`, and cluster sizes `a_size` and `b_size`, return a list representing a new row of `m`. Do **not** modify `m` in this function; just generate the new row list.\n\nTo generate the new row list:\n* For every cluster *X* in the matrix:\n  * Call `new_dist()` to find $$d_{(A \\cup B),X}$$\n  * Add this distance to the new row.\n* Add an entry of *0.0* to represent the distance from the new cluster to itself.","metadata":{}},{"cell_type":"code","source":"def create_new_row(m: List[List[float]], row_a: int, row_b: int, a_size: int, b_size: int):\n    new_list=[]\n    for i in range(0, len(m)):\n        d_a_x = m[row_a][i]\n        d_b_x = m[row_b][i]\n        n_dist = new_dist(a_size, b_size, d_a_x, d_b_x)\n        new_list.append(n_dist)\n    new_list.append(0.0)\n    return new_list","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.405262Z","iopub.execute_input":"2022-02-13T21:27:36.405526Z","iopub.status.idle":"2022-02-13T21:27:36.412214Z","shell.execute_reply.started":"2022-02-13T21:27:36.405498Z","shell.execute_reply":"2022-02-13T21:27:36.411487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_row = create_new_row(nested_copy(dmat), 1, 3, 1, 1)\nassess(new_row, \n       [0.8536675922317023, 0.3440970301209663, 0.9656172550022594, 0.34409703012096615, 0.0])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.419681Z","iopub.execute_input":"2022-02-13T21:27:36.419984Z","iopub.status.idle":"2022-02-13T21:27:36.429202Z","shell.execute_reply.started":"2022-02-13T21:27:36.419953Z","shell.execute_reply":"2022-02-13T21:27:36.428254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Given a row for a new cluster `X` created by `create_new_row()`, we now want to add it back to the original matrix. This requires not only appending the row to the matrix, but also adding a column to each existing row to keep the matrix symmetric.","metadata":{}},{"cell_type":"code","source":"def add_row_to(m: List[List[float]], new_row: List[float]):\n    m.append(new_row)\n    l=len(m)-1\n    for i in range(0, len(m)-1):\n        m[i].append(0.0)\n        m[i][l]=m[l][i]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.444327Z","iopub.execute_input":"2022-02-13T21:27:36.444604Z","iopub.status.idle":"2022-02-13T21:27:36.45107Z","shell.execute_reply.started":"2022-02-13T21:27:36.444575Z","shell.execute_reply":"2022-02-13T21:27:36.450142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"m_copy = nested_copy(dmat)\nadd_row_to(m_copy, new_row)\nlabels = list(filename2document) + ['X']\npretty_matrix(labels, labels, m_copy)\nm_copy == [[0.0, 0.740251794063685, 0.982331986879515, 0.9670833903997196, 0.8536675922317023],\n           [0.740251794063685, 1.1102230246251565e-16, 0.9785579200110728, 0.6881940602419325, 0.3440970301209663],\n           [0.982331986879515, 0.9785579200110728, 2.220446049250313e-16, 0.952676589993446, 0.9656172550022594],\n           [0.9670833903997196, 0.6881940602419325, 0.952676589993446, -2.220446049250313e-16, 0.34409703012096615],\n           [0.8536675922317023, 0.3440970301209663, 0.9656172550022594, 0.34409703012096615, 0.0]]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.499316Z","iopub.execute_input":"2022-02-13T21:27:36.499652Z","iopub.status.idle":"2022-02-13T21:27:36.512195Z","shell.execute_reply.started":"2022-02-13T21:27:36.499617Z","shell.execute_reply":"2022-02-13T21:27:36.511304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, write a function that brings in a distance matrix and creates clusters using the UPGMA algorithm. This algorithm  iteratively combines the two closest clusters until there is one single tree. Here is the pseudocode for this algorithm:\n\n* Create the initial list of leaf clusters\n* While we still have multiple independent clusters\n  * Find the nearest two clusters according to our distance matrix\n  * Join these two clusters to make a new cluster\n  * Add new distances to our matrix for every row and column between it and the new cluster\n* Return the list of created clusters, minus the initial leaves","metadata":{}},{"cell_type":"code","source":"def upgma(m: List[List[float]]) -> List[Tuple[int, int, float, int]]:\n    m_copy = nested_copy(m)\n    list_of_tuples = init_clusters(m_copy)\n    current_clusters = []\n    exclude=set()\n    i=0\n    while i < len(m)-1:\n        closest=nearest(m_copy, exclude) #c[0] = vec1, c[1] = vec2, c[2] = distance\n        exclude.add(closest[0])\n        exclude.add(closest[1])\n        new_row =create_new_row(m_copy, closest[0], closest[1], list_of_tuples[closest[0]][3], list_of_tuples[closest[1]][3])\n        add_row_to(m_copy, new_row)\n        sum1=list_of_tuples[closest[1]][3]+list_of_tuples[closest[0]][3]\n        current_clusters.append((closest[0], closest[1], closest[2], sum1))\n        list_of_tuples.append((closest[0], closest[1], closest[2], sum1))\n        i+=1\n    return current_clusters","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.60847Z","iopub.execute_input":"2022-02-13T21:27:36.608916Z","iopub.status.idle":"2022-02-13T21:27:36.622807Z","shell.execute_reply.started":"2022-02-13T21:27:36.608871Z","shell.execute_reply":"2022-02-13T21:27:36.622102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assess(upgma(dmat), \n       [(1, 3, 0.6881940602419325, 2),\n        (0, 4, 0.8536675922317023, 3),\n        (2, 5, 0.9711888322946779, 4)])","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.642087Z","iopub.execute_input":"2022-02-13T21:27:36.64268Z","iopub.status.idle":"2022-02-13T21:27:36.652237Z","shell.execute_reply.started":"2022-02-13T21:27:36.642634Z","shell.execute_reply":"2022-02-13T21:27:36.651439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 4 - Dendrogram","metadata":{}},{"cell_type":"markdown","source":"Finally, we can use the $dendrogram$ function in the $scipy.hierarchy$ module to draw the resulting tree from our clustered data.","metadata":{}},{"cell_type":"code","source":"def tf_only_matrix(tf: Dict[str,Dict[str,int]]) -> List[List[float]]:\n    return [[counts.get(term, 0) for term in terms] \n            for filename, counts in tf.items()]\n\ndef plot_dendrogram(filename2document: Dict[str,str], title: str, ignore_idf=False):\n    tf = term_freqs(filename2document)\n    terms = all_terms(filename2document)\n    idf = inv_doc_freqs(filename2document, terms)\n    if ignore_idf:\n        c = upgma(dist_matrix(tf_only_matrix(tf)))\n    else:\n        c = upgma(dist_matrix(find_tfidf(tf, idf, terms)))\n    plt.figure()\n    plt.figure(figsize=(10, 10))\n    dn = hierarchy.dendrogram(c, labels = list(filename2document), leaf_rotation=90)\n    plt.title(f\"UPGMA Clustering: {title}\")\n    plt.ylabel(\"total distance\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.789537Z","iopub.execute_input":"2022-02-13T21:27:36.790274Z","iopub.status.idle":"2022-02-13T21:27:36.799507Z","shell.execute_reply.started":"2022-02-13T21:27:36.790222Z","shell.execute_reply":"2022-02-13T21:27:36.798807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_dendrogram(filename2document, \"Winter Sentences using tf-idf\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:36.80501Z","iopub.execute_input":"2022-02-13T21:27:36.805388Z","iopub.status.idle":"2022-02-13T21:27:37.082477Z","shell.execute_reply.started":"2022-02-13T21:27:36.805335Z","shell.execute_reply":"2022-02-13T21:27:37.079009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part 5 - Experiments and Discussion","metadata":{}},{"cell_type":"markdown","source":"Draw a dendrogram and discuss the results of your clustering for each of the following four experiments\n* Poems using tf only\n* Poems using tf-idf\n* Books using tf only\n* Books using tf-idf","metadata":{}},{"cell_type":"code","source":"def tf_only_matrix(tf: Dict[str,Dict[str,int]]) -> List[List[float]]:\n    return [[counts.get(term, 0) for term in terms] \n            for filename, counts in tf.items()]","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:37.084411Z","iopub.execute_input":"2022-02-13T21:27:37.084831Z","iopub.status.idle":"2022-02-13T21:27:37.092107Z","shell.execute_reply.started":"2022-02-13T21:27:37.084786Z","shell.execute_reply":"2022-02-13T21:27:37.090445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"poems = file_dictionary('/kaggle/input/csci-270-poems-2022')\n\nplot_dendrogram(poems, \"Poems, TF only\", True)\nplot_dendrogram(poems, \"Poems, TF-IDF\")\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:37.09376Z","iopub.execute_input":"2022-02-13T21:27:37.094843Z","iopub.status.idle":"2022-02-13T21:27:39.078006Z","shell.execute_reply.started":"2022-02-13T21:27:37.094794Z","shell.execute_reply":"2022-02-13T21:27:39.077012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Poem Discussion\n\n1. Compare and contrast the TF-only clustering with the TF-IDF clustering. Which corresponds better to your intuition about what makes the poems similar? Why?\n    \n    I expected the graphs to cluster the books in a similiar order in both graphs. Instead they are compared in various different orders. I expected them to be less similiar in the IDF graph because of the lack of meaningful words. \n\n\n\n2. Carefully read two poems that are relatively close to your poem in the TF-IDF clustering, and two poems that are distant from your poem. What specific aspects of these poems do you think are represented well by the TF-IDF concept? What are some aspects that TF-IDF overlooks?\n\n    (My poem is The road not taken, I compared it to (close) Things/Viva La Vida, and (distant)ThunderRoad/Misery Business)\n    I think that the tf-idf clustering is able to capture the overall theme of a poem well. It seems like the poems more similiar to mine were talking about similiar subjects. Specifically personifying things or events, and longing for the past, or to change it. The poems that were more closely related to my poem were also just more alike in overall structure where the more distant poems had a quite different structure. \n    \n","metadata":{}},{"cell_type":"code","source":"books = file_dictionary('/kaggle/input/csci-270-books-2022')\n\nplot_dendrogram(books, \"Books, TF only\", True)\nplot_dendrogram(books, \"Books, TF-IDF\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:27:39.079791Z","iopub.execute_input":"2022-02-13T21:27:39.080136Z","iopub.status.idle":"2022-02-13T21:58:06.683839Z","shell.execute_reply.started":"2022-02-13T21:27:39.080104Z","shell.execute_reply":"2022-02-13T21:58:06.682881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Book Discussion\n\n1. Compare and contrast the TF-only clustering with the TF-IDF clustering. Which corresponds better to your intuition about what makes the books similar? Why?\n\n    The Tf-clustering seems to be more inline with what my assumptions were. It seems books dealing heavily with adventure were clustered much more appropriately. At least it makes sense to me that 'King arthur', 'The Lion The Witch and The Wardrobe', & 'Robin Hood' are more similiar to huck-finn than the great gatsby. \n\n2. Skim a few pages of two books that are relatively close to your book in the TF-IDF clustering, and two books that are distant from your book.  What specific aspects of these books do you think are represented well by the TF-IDF concept? What are some aspects that TF-IDF overlooks?\n\n    It makes sense that treasure island would be closely paired with huck-finn. Not only because they both have characters named jim, but because their plots both rely heavily the adventuring the characters do. The next cloely related book is the great gatsby. I cannot think of any particular reason why this would be so closely related to huck finn. I feel like they deal with very different topics. It does makes sense that books like darth plagueis and do androids dream of sheep, are clustered away from huck-finn because their science fiction nature.","metadata":{}},{"cell_type":"markdown","source":"## Chapter Analysis\n\nBreak up your book into a dictionary where the keys are chapter names or numbers and the values are the contents of each chapter (or other pertinent subdivision).  Then apply `plot_dendrogram()`. Examine the dendrogram, and then answer the questions below.","metadata":{}},{"cell_type":"code","source":"## Write code here to create the Chapter Analysis dendrogram.\nchapters = books['huck-finn_fixed.txt'].split('CHAPTER')\n\ndis = {i: chapters[i] for i in range(1, len(chapters))}\nplot_dendrogram(dis, \"Huckleberry Finn\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T21:58:06.685207Z","iopub.execute_input":"2022-02-13T21:58:06.685439Z","iopub.status.idle":"2022-02-13T21:58:37.406634Z","shell.execute_reply.started":"2022-02-13T21:58:06.685411Z","shell.execute_reply":"2022-02-13T21:58:37.405715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Chapter Analysis Questions\n\n1. Examine the various clusters of chapters. To what extent does the similarity among chapters correspond to different stages of the story and plot?\n\n      The two most similiar chapters are 8, and 14. chapter 8 is when huck and jim meet up to begin their adventure. There is tension between the two of them and huck has a moral delema as to whether or not to turn jim in. Chapter 14 is huck retelling a bible story about king solomon to jim. The next closest related is chapter 18, which deals with the two feuding families huck and jim get caught between. They have to escape the battle that happens between the groups. The next closest chapter is 15, where Huck and jim lose each other on the river. Chapter 23 is next & deals with the two hobos who pretend to be royalty on the raft. Chapter 4 is the only particular outlier in this group. It takes place before the river adventure starts, which seems to be the only commonality between these other chapters. It deals with Huckleberry giving away his fortune because he fears his father will come back and take it from him. The final closely related chapter is 16. In this chapter Huck has to sneak jim past patrols/cities of slave search parties. I cannot discern a single plot similiarity between all of these chapters. It just seems that most of them are indivudual adventures that take place on the river.  \n\n2. Does this clustering of chapters suggest to you any new insights about the book? Explain.\n\n    Nothing particular stands out from these chapters. They all seem to deal with heavy/intense subjects on their own, but none of their dramas are related. The only thing I can think of is that they are all stressful adventures by themselves.","metadata":{}}]}